{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 14:01:40.455969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741784500.482329  845799 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741784500.491472  845799 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 14:01:40.523009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40, 25, 512)\n",
      "y_train shape: (40, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Load CSV files\n",
    "df_one = pd.read_csv(\"/home/harald_stabbetorp/Master/e-prop_master_nmbu/sound_fet/one_encoded_features.csv\")  # Shape: (num_samples, 12800)\n",
    "df_two = pd.read_csv(\"/home/harald_stabbetorp/Master/e-prop_master_nmbu/sound_fet/two_encoded_features.csv\")  # Shape: (num_samples, 12800)\n",
    "df_silence = pd.read_csv(\"/home/harald_stabbetorp/Master/e-prop_master_nmbu/sound_fet/zeros.csv\")  # Shape: (num_samples, 12800)\n",
    "\n",
    "# Reshape to (num_samples, 25, 512)\n",
    "X_one = df_one.values.reshape(-1, 25, 512)\n",
    "X_two = df_two.values.reshape(-1, 25, 512)\n",
    "X_silence = df_silence.values.reshape(-1, 25, 512)\n",
    "\n",
    "# Define labels: Silence=0, \"one\"=1, \"two\"=2\n",
    "y_silence = np.zeros((X_silence.shape[0], 1))\n",
    "y_one = np.ones((X_one.shape[0], 1))  # Label \"one\" as 1\n",
    "y_two = np.full((X_two.shape[0], 1), 2)  # Label \"two\" as 2\n",
    "\n",
    "# Concatenate sequences in alternating order\n",
    "X_combined = np.vstack((X_silence, X_one, X_silence, X_two))\n",
    "y_combined = np.vstack((y_silence, y_one, y_silence, y_two))\n",
    "\n",
    "# Repeat the sequence 10 times to make the dataset longer\n",
    "X_combined = np.tile(X_combined, (10, 1, 1))  # Repeat X_combined 10 times\n",
    "y_combined = np.tile(y_combined, (10, 1))     # Repeat y_combined 10 times\n",
    "\n",
    "# Shuffle the dataset (important)\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined, random_state=42)\n",
    "\n",
    "# Split into training and testing (using the same data for both)\n",
    "X_train, X_test = X_combined, X_combined\n",
    "y_train, y_test = y_combined, y_combined\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  # (total_samples * 10, 25, 512)\n",
    "print(\"y_train shape:\", y_train.shape)  # (total_samples * 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 14:01:49.054092: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.4062 - loss: 1.3132 - val_accuracy: 0.1250 - val_loss: 1.0634\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.5938 - loss: 0.8602 - val_accuracy: 0.1250 - val_loss: 1.0073\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.5938 - loss: 0.7664 - val_accuracy: 1.0000 - val_loss: 0.9984\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 1.0000 - val_loss: 0.9778\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 0.5525 - val_accuracy: 1.0000 - val_loss: 0.9569\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 0.4966 - val_accuracy: 1.0000 - val_loss: 0.9400\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.4653 - val_accuracy: 1.0000 - val_loss: 0.9267\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 0.4459 - val_accuracy: 1.0000 - val_loss: 0.9148\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.4337 - val_accuracy: 1.0000 - val_loss: 0.9021\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 0.4241 - val_accuracy: 1.0000 - val_loss: 0.8870\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 0.4149 - val_accuracy: 1.0000 - val_loss: 0.8689\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 0.4054 - val_accuracy: 1.0000 - val_loss: 0.8469\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 1.0000 - loss: 0.3945 - val_accuracy: 1.0000 - val_loss: 0.8189\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.3811 - val_accuracy: 1.0000 - val_loss: 0.7820\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - accuracy: 1.0000 - loss: 0.3638 - val_accuracy: 1.0000 - val_loss: 0.7299\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.3394 - val_accuracy: 1.0000 - val_loss: 0.6534\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 0.3038 - val_accuracy: 1.0000 - val_loss: 0.5372\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 0.2498 - val_accuracy: 1.0000 - val_loss: 0.3654\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 0.1699 - val_accuracy: 1.0000 - val_loss: 0.1599\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe447ca99c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define model\n",
    "inputs = Input(shape=(25, 512))\n",
    "x = LSTM(256, return_sequences=False)(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)  # 3 output classes: Silence, One, Two\n",
    "\n",
    "model = Model(inputs, x)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Test Accuracy: 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Predicted Classes: [2 0 2 0 0 0 1 2 2 0 1 1 1 2 0 0 1 0 0 1 1 2 1 1 1 0 0 0 2 2 2 0 0 0 0 0 2\n",
      " 0 0 0]\n",
      "True Classes: [2. 0. 2. 0. 0. 0. 1. 2. 2. 0. 1. 1. 1. 2. 0. 0. 1. 0. 0. 1. 1. 2. 1. 1.\n",
      " 1. 0. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class index\n",
    "\n",
    "print(\"Predicted Classes:\", y_pred_classes)  # Show first 10 predictions\n",
    "print(\"True Classes:\", y_test.flatten())  # Show first 10 actual labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
